# In-Context-Learning-ICL-_MT

In this experiment, we aim to investigate the efficacy of machine translation through In-Context Learning (ICL) for converting English to Spanish. Using the WMT-14 dataset, which includes diverse language phenotypes and structures, our approach involves prompting pre-trained models with varying numbers of example translations, known as "shots." We explore zero-shot, two-shot, and few-shot scenarios to evaluate how well the models perform translations based on the provided context. We use five pre-trained models: MAMBA-2.8b, Btlm-3b, Mistral- 7B, Pythia-2.8B, and LLama-7B Testing involves translating sentences such as "The book is on the table" and "The flowers are blooming in the garden" to Spanish. We have used BLEU score to evaluate the translation accuracy.
